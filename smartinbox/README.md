# SmartInbox Agentensystem

> Ein KI-gest√ºtztes Multi-Agenten-System f√ºr intelligente E-Mail-Verarbeitung

Workshop-Projekt zum Thema "KI-Agentensysteme" - demonstriert Agentenarchitektur, Orchestrierung und Modellanbindung in einem praxisnahen Szenario.

## √úberblick

SmartInbox ist ein vollst√§ndiges, webbasiertes Agentensystem, das eingehende E-Mails automatisch klassifiziert und an spezialisierte Agenten weiterleitet. Das System nutzt **LangGraph** f√ºr die Orchestrierung und kann mit lokalen Open-Source-Modellen (z.B. √ºber Ollama) betrieben werden.

### Features

- **Automatische E-Mail-Klassifikation** in 5 Kategorien
- **5 spezialisierte Agenten** f√ºr unterschiedliche E-Mail-Typen
- **Interaktiver Chat-Agent** f√ºr Benutzerinteraktion
- **Visuelle Agenten-Log-Darstellung** im Frontend
- **React-basierte Web-UI** mit Echtzeit-Updates
- **Vollst√§ndig lokal lauff√§hig** (keine Cloud-Abh√§ngigkeiten)

## Architektur

### System-Komponenten

```mermaid
graph TB
    A[E-Mail Eingang] --> B[Orchestrator Agent]
    B -->|Klassifikation| C{E-Mail Typ?}

    C -->|quote_request| D[Angebotsagent]
    C -->|invoice| E[Rechnungsagent]
    C -->|support| F[Supportagent]
    C -->|newsletter| G[Newsletteragent]
    C -->|appointment| H[Terminagent]

    D --> I[Chat-Agent]
    E --> I
    F --> I
    G --> I
    H --> I

    I --> J[Benutzer-Response]

    style B fill:#667eea
    style I fill:#764ba2
    style D fill:#48bb78
    style E fill:#48bb78
    style F fill:#48bb78
    style G fill:#48bb78
    style H fill:#48bb78
```

### Agenten-√úbersicht

| Agent | Aufgabe | Datenquellen |
|-------|---------|--------------|
| **Orchestrator** | Klassifiziert E-Mails in 5 Kategorien | E-Mail-Inhalt |
| **Angebotsagent** | Analysiert Anfragen, schl√§gt Produkte vor | Mock-CRM-Daten |
| **Rechnungsagent** | Pr√ºft Rechnungen auf Vollst√§ndigkeit | E-Mail-Inhalt |
| **Supportagent** | Beantwortet Fragen via FAQ | `support_faq.json` |
| **Newsletteragent** | Extrahiert Schlagzeilen & Zusammenfassung | E-Mail-Inhalt |
| **Terminagent** | Schl√§gt Termine vor, fragt fehlende Infos ab | Kalender-Slots |
| **Chat-Agent** | Kommuniziert Ergebnisse an Benutzer | Alle Agentenergebnisse |

### Technologie-Stack

**Backend:**
- Python 3.11+
- FastAPI (REST API)
- LangGraph (Agenten-Orchestrierung)
- LangChain (LLM-Integration)
- Ollama (lokales LLM)

**Frontend:**
- React 18
- Vite (Build-Tool)
- Lucide Icons
- Vanilla CSS

## Installation

### Voraussetzungen

- Python 3.11 oder h√∂her
- Node.js 18 oder h√∂her
- Ollama (f√ºr lokales LLM)
- Git

### 1. Repository klonen

```bash
git clone <repository-url>
cd smartinbox
```

### 2. Backend einrichten

```bash
cd backend

# Virtual Environment erstellen (empfohlen)
python -m venv venv

# Virtual Environment aktivieren
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# Dependencies installieren
pip install -r requirements.txt

# .env-Datei erstellen
cp .env.example .env

# .env anpassen (optional)
# Standardm√§√üig verwendet das System Ollama auf localhost:11434
```

### 3. Ollama installieren und Modell laden

```bash
# Ollama installieren (siehe https://ollama.ai)
# Dann ein Modell herunterladen:

ollama pull llama2:13b

# Alternativ andere Modelle:
# ollama pull mistral
# ollama pull llama2:7b (schneller, weniger genau)
```

### 4. Frontend einrichten

```bash
cd ../frontend

# Dependencies installieren
npm install

# Optional: .env f√ºr Frontend erstellen
# echo "VITE_API_URL=http://localhost:8000/api" > .env
```

## Verwendung

### System starten

**Terminal 1 - Backend:**
```bash
cd backend
source venv/bin/activate  # bzw. venv\Scripts\activate auf Windows
python main.py
```

Das Backend l√§uft auf: `http://localhost:8000`
API-Dokumentation: `http://localhost:8000/docs`

**Terminal 2 - Frontend:**
```bash
cd frontend
npm run dev
```

Das Frontend l√§uft auf: `http://localhost:5173`

### Demo durchf√ºhren

1. √ñffnen Sie `http://localhost:5173` im Browser
2. Verwenden Sie eine der vorausgef√ºllten Beispiel-E-Mails:
   - **Angebotsanfrage** - zeigt CRM-Integration
   - **Rechnung** - demonstriert Validierung
   - **Support** - nutzt FAQ-Datenbank
   - **Newsletter** - extrahiert Schlagzeilen
   - **Termin** - schl√§gt Zeitfenster vor

3. Beobachten Sie:
   - **E-Mail-Klassifikation** (Orchestrator)
   - **Agenten-Aktivit√§t** im Log (rechts)
   - **Chat-Antwort** des Systems

4. Testen Sie die **Chat-Interaktion**:
   - Beantworten Sie R√ºckfragen des Systems
   - Stellen Sie Zusatzfragen

## Projektstruktur

```
smartinbox/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ agents/              # Agenten-Implementierungen
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ orchestrator.py  # E-Mail-Klassifikation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ quote_agent.py   # Angebotsagent
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ invoice_agent.py # Rechnungsagent
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ support_agent.py # Supportagent
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ newsletter_agent.py # Newsletteragent
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ appointment_agent.py # Terminagent
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chat_agent.py    # Chat-Assistent
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ state.py         # State-Definitionen
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ workflow.py      # LangGraph Workflow
‚îÇ   ‚îú‚îÄ‚îÄ api/                 # FastAPI Routes
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ routes.py
‚îÇ   ‚îú‚îÄ‚îÄ config/              # Konfiguration
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ settings.py
‚îÇ   ‚îú‚îÄ‚îÄ utils/               # Hilfsfunktionen
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ llm.py          # LLM-Client
‚îÇ   ‚îú‚îÄ‚îÄ main.py              # Backend-Einstiegspunkt
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt     # Python-Dependencies
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/      # React-Komponenten
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ MailInbox.jsx      # E-Mail-Eingabe
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ChatInterface.jsx  # Chat-UI
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ AgentLog.jsx       # Agenten-Log
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/        # API-Client
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ api.js
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ App.jsx          # Hauptkomponente
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ App.css          # Styling
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ main.jsx         # React-Einstiegspunkt
‚îÇ   ‚îú‚îÄ‚îÄ package.json
‚îÇ   ‚îî‚îÄ‚îÄ vite.config.js
‚îú‚îÄ‚îÄ prompts/                 # Prompt-Templates
‚îÇ   ‚îú‚îÄ‚îÄ orchestrator.txt
‚îÇ   ‚îú‚îÄ‚îÄ quote.txt
‚îÇ   ‚îú‚îÄ‚îÄ invoice.txt
‚îÇ   ‚îú‚îÄ‚îÄ support.txt
‚îÇ   ‚îú‚îÄ‚îÄ newsletter.txt
‚îÇ   ‚îú‚îÄ‚îÄ appointment.txt
‚îÇ   ‚îî‚îÄ‚îÄ chat.txt
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ mails/               # Beispiel-E-Mails
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ example_mails.json
‚îÇ   ‚îî‚îÄ‚îÄ faq/                 # FAQ-Datenbank
‚îÇ       ‚îî‚îÄ‚îÄ support_faq.json
‚îî‚îÄ‚îÄ README.md
```

## Workflow-Ablauf

### Detaillierter Ablauf einer E-Mail-Verarbeitung

```mermaid
sequenceDiagram
    participant U as User/Frontend
    participant API as FastAPI Backend
    participant O as Orchestrator
    participant SA as Spezialist-Agent
    participant CA as Chat-Agent
    participant LLM as Ollama LLM

    U->>API: POST /process-email
    API->>O: classify(email)
    O->>LLM: Klassifiziere E-Mail
    LLM-->>O: {classification: "quote_request"}
    O-->>API: State mit Klassifikation

    API->>SA: process(state)
    SA->>LLM: Analysiere Angebotsanfrage
    LLM-->>SA: {requested_products, recommendations}
    SA-->>API: State mit Ergebnissen

    API->>CA: process(state)
    CA->>LLM: Generiere Benutzerantwort
    LLM-->>CA: Freundliche Zusammenfassung
    CA-->>API: State mit finaler Antwort

    API-->>U: {classification, agent_steps, messages}
```

## Anpassung & Erweiterung

### Neue Agenten hinzuf√ºgen

1. **Agent-Klasse erstellen** in `backend/agents/`:
```python
class MyNewAgent:
    def __init__(self, prompts: dict):
        self.system_prompt = prompts.get("mynew", "...")

    def process(self, state: SmartInboxState) -> SmartInboxState:
        # Agent-Logik
        return state
```

2. **Workflow erweitern** in `workflow.py`:
```python
workflow.add_node("mynew_agent", self._route_to_mynew_agent)
```

3. **Prompt-Template erstellen**: `prompts/mynew.txt`

### Prompts anpassen

Alle Prompts befinden sich in `prompts/`. Passen Sie diese an Ihre Anforderungen an:

```bash
prompts/
‚îú‚îÄ‚îÄ orchestrator.txt  # Klassifikationslogik
‚îú‚îÄ‚îÄ quote.txt         # Angebotsverhalten
‚îî‚îÄ‚îÄ ...
```

### Andere LLMs verwenden

**OpenAI/Claude:**
```python
# In utils/llm.py:
from langchain_openai import ChatOpenAI

self.llm = ChatOpenAI(model="gpt-4")
```

**Andere lokale Modelle:**
```bash
# Modell in Ollama laden:
ollama pull mistral
ollama pull codellama

# In .env anpassen:
OLLAMA_MODEL=mistral
```

## Troubleshooting

### Backend startet nicht

```bash
# Pr√ºfen Sie die Python-Version:
python --version  # Muss >= 3.11 sein

# Dependencies neu installieren:
pip install --upgrade -r requirements.txt
```

### Ollama-Verbindung fehlgeschlagen

```bash
# Pr√ºfen Sie, ob Ollama l√§uft:
curl http://localhost:11434/api/tags

# Ollama neu starten:
ollama serve
```

### Frontend l√§dt nicht

```bash
# Node-Module neu installieren:
rm -rf node_modules package-lock.json
npm install

# Port bereits belegt? Port √§ndern:
# In vite.config.js: server: { port: 5174 }
```

### LLM antwortet nicht im JSON-Format

- Verwenden Sie ein st√§rkeres Modell (z.B. `llama2:13b` statt `llama2:7b`)
- Passen Sie die Prompts an und geben Sie mehr Beispiele
- Erh√∂hen Sie die `temperature` in `utils/llm.py` (f√ºr mehr Kreativit√§t) oder senken Sie sie (f√ºr mehr Konsistenz)

## Workshop-Szenarien

### Szenario 1: Vollst√§ndiger Workflow
1. Senden Sie die Beispiel-Angebotsanfrage
2. Beobachten Sie die Klassifikation
3. Sehen Sie, wie der Angebotsagent CRM-Daten nutzt
4. Interagieren Sie mit dem Chat-Agenten

### Szenario 2: Fehlende Informationen
1. Erstellen Sie eine unvollst√§ndige Terminanfrage
2. Beobachten Sie, wie der Agent fehlende Infos identifiziert
3. Beantworten Sie die R√ºckfragen im Chat

### Szenario 3: FAQ-Nutzung
1. Senden Sie eine Support-Anfrage zum Thema "Login-Problem"
2. Sehen Sie, wie der Agent die FAQ durchsucht
3. Erhalten Sie eine strukturierte Antwort

## Lizenz

Dieses Projekt ist f√ºr Bildungszwecke konzipiert.

## Kontakt & Support

Bei Fragen zum Workshop oder technischen Problemen:
- Erstellen Sie ein Issue im Repository
- Kontaktieren Sie den Workshop-Leiter

---

**Viel Erfolg beim Workshop!** üöÄ
